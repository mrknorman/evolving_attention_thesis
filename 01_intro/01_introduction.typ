#set page(numbering: "1", number-align: center)
#set heading(numbering: "1.1.1")

#counter(page).update(1)
#counter(heading).update(0)

#set math.equation(numbering: it => {[1.#it]})
#counter(math.equation).update(0)

#counter(figure).update(0)


= Introduction

We live in an exciting time. Now dawns an age of remarkable confluence and innovation; machine learning and artificial intelligence stand poised to remake almost every aspect of science, technology, and everyday life. At the same time, our understanding of the world is increasing with ever more fervour. The era of gravitational-wave astronomy has well and truly begun, and bountiful volumes of new data will soon be at our fingertips. The machine learning community is unlocking novel new tools every month, and it would be an odious missed opportunity not to turn some of these powerful techniques onto the data hidden beneath interferometer noise.

This thesis is an exploration of the use of artificial neural networks to solve problems within gravitational-wave data analysis. Certainly, it is not the first work to attempt such a task, and indeed the intersection between the two fields has attracted much interest in recent years, perhaps that is unsurprising --- both fields are new and exciting; it is only natural to try and merge the two. Despite this busy environment, we find that there is some room for innovation. Crucially, we try and work upward from first principles, and present our results in a manner that is easily comparable with other studies. The entirety of the codebase used in the creation of this thesis and all associated work is available online through this URL: #link("https://github.com/mrknorman/evolving_attention"), although, unfortunately, some of the data acquisition methods are gated behind LIGO collaboration membership.

@gravitational-waves-sec and @machine-learning-sec, are introductory chapters that present background information in the areas of gravitational waves and machine learning respectively. They aim to both contextualize the data analysis methods presented throughout the rest of the thesis and in the case of the machine learning chapter introduce many of the analysis methods and nomenclature used throughout.  @gravitational-waves-sec gives a brief introduction to gravitational wave science, but it is considered less necessary for the understanding of this thesis than the following chapter. @machine-learning-sec in a more rigorous examination of the basics of artificial neural networks, which form the backbone of this work.

@application-sec acts as a general methodology for the data analysis techniques used in later chapters and introduces the custom software that was generated to facilitate the faster iteration of machine learning model training: cuPhenom @cuphenom_ref a GPU implementation of IMRPhenomD, and GravyFlow, a custom data acquisition and model training pipeline designed for machine learning in gravitational wave science. In @application-sec we also review the relevant literature, to explore the work others have contributed to the field, before performing a series of experiments to evaluate the performance of unspecialized artificial neural networks to show the necessity of experimentation. We conclude this chapter by recreating some prominent results from the literature, which then act as a baseline for comparison in further chapters.

When designing artificial neural network models, there are a large number of free parameters that are not optimised during model training, these parameters are known as hyperparameters. They pose a significant barrier when attempting to find optimal deep-learning solutions for data analysis tasks. Often, hyperparameter optimization is performed by human-guided trial and error. This increases the already difficult task of comparisons between the performance of models presented in the literature. It is never clear how optimal the hyperparameter optimisation process has been. @dragonn-sec presents Dragonn, a hyperparameter optimisation method that utilises genetic algorithms to find optimal network solutions. It is hoped that by exploring methods for automatic hyperparameter selection we might move a little toward a more robust and repeatable method for optimizing and comparing the performance of different model architectures. This work was used in the early development of the models that form the core of the MLy rapid burst detection pipeline @MLy.

@skywarp-sec explores the use of a more contemporary neural network architecture, the transformer @attention_is_all_you_need, which has found the most prominent use in natural language processing applications such as ChatGPT @chatgpt_ref. More precisely, we explore the use of the core innovations presented by the initial transformer paper @attention_is_all_you_need, the attention mechanism. We apply attention-based models to the CBC detection problem and find a marginal improvement over more widely used convolutional neural networks.

In @crosswave-sec we focus on a more specific problem that is currently not an issue but will become a major component of search pipelines when next-generation gravitational wave detectors come online. We explore the possibility that artificial neural networks can aid in the differentiation between single gravitational wave signals and pairs of overlapping gravitational wave signals. We also build a large network utilizing cross-attention layers in order to attempt to extract the parameters from both signals in an overlapping pair. We do this both to provide an established parameter estimation method with more information to improve its operation and as an exercise in its own right, potentially as a prelude to an entire machine-learning-based method to perform parameter estimation on overlapping signals.